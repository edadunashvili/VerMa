{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Auswertung - abcd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README\n",
    "\n",
    "Der Code visualisiert die Verkettung von Motiven innerhalb eines Märchentyps.\n",
    "\n",
    "Ein Motiv wird als Markupelement dargestellt und besteht jeweils aus einem 4-Tupel (a=Typnummer, b = Sinn und Zweck der Handlung, c = die Handlung, d = die handlungstragende Figur bzw. Figuren).\n",
    "\n",
    "Anpassbare Zeilen:\n",
    "\n",
    "(#1) Die Index des in Betracht bezogenen Typs kann durch die Variable 'mZahl' angepasst werden.\n",
    "\n",
    "(#2) Durch die Variable 'mWert' wird ein Motiv als Anhaltpunkt in der visualisierten Motivkette bestimmt. Dieser Wert wird aus der generierten Liste (siehe #149) entnommen, nachdem als die Variable 'mZahl' (siehe #1) bestimmt und der Code ausgeführt ist.\n",
    "\n",
    "(#3) Die Variable 'häufigkeit' bestimmt die Häufigkeit des Auftretens der Verbindung zwischen den Motiven.\n",
    "\n",
    "(#6) Pfad zu der Inputdatei.\n",
    "\n",
    "(#9) Der Attributwert bestimmt die Herkunft der zu analysierenden Textgruppe (des Repertoires). Die Filter können mit den 'or' und 'and' Operatoren ergänzt werden, z. B.:  \n",
    "\n",
    "if ('deu' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "\n",
    "    or 'ita' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:21.683424Z",
     "start_time": "2024-01-25T21:11:21.667056Z"
    }
   },
   "outputs": [],
   "source": [
    "mZahl = \"a551\"  #1 Typnummer eingeben\n",
    "\n",
    "mWert = \"a551:h:Krankheit:rHH\"  #2 Ein konkretes Markupelement eingeben\n",
    "\n",
    "haeufigkeit = 2  #3 Eine ganze Zahl eingeben = Häufigkeit eines Markupelements in den ausgewerteten Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:22.943093Z",
     "start_time": "2024-01-25T21:11:21.693040Z"
    }
   },
   "outputs": [],
   "source": [
    "maerchen = \"\"  #4 Eine leere Zeichenkette, in der Daten für Märchen gesammelt werden\n",
    "\n",
    "import xml.etree.ElementTree as ET  #5 Importieren der ElementTree-Bibliothek zum Parsen von XML\n",
    "\n",
    "root_node = ET.parse('Textkorpus.xml').getroot()  #6 Parsen der XML-Datei und Zugriff auf das Wurzelelement\n",
    "\n",
    "never_saved = True  #7 Ein boolean-Wert, der angibt, ob Daten bereits gespeichert wurden oder nicht\n",
    "\n",
    "#8 Iteration durch jedes 'text'-Element in der XML-Datei\n",
    "for ganze in root_node.findall(\".//{http://www.tei-c.org/ns/1.0}text\"):\n",
    "    \n",
    "    #9 Überprüfung, ob das gesuchte Attribut in der 'id'-Eigenschaft des 'text'-Elements vorhanden ist\n",
    "    if ('deu' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']):\n",
    "        \n",
    "        #10 Iteration durch jeden Absatz im 'body' des 'text'-Elements.\n",
    "        for body in ganze.findall(\".//{http://www.tei-c.org/ns/1.0}body\"):\n",
    "            for absatz in body.findall(\".//{http://www.tei-c.org/ns/1.0}p\"):\n",
    "                #11 Iteration durch jede 'seg'-Phrase im Absatz.\n",
    "                for phrase in absatz.findall(\".//{http://www.tei-c.org/ns/1.0}seg\"):\n",
    "                    #12 Extrahieren von Labels und Inhalten aus den Attributen und dem Text der Phrase.\n",
    "                    labela = phrase.attrib['{www.dglab.uni-jena.de/vmf/a}ana']\n",
    "                    labelb1 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b1}ana']\n",
    "                    labelb2 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b2}ana']\n",
    "                    labelb3 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b3}ana']\n",
    "                    labelb4 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b4}ana']\n",
    "                    labelb5 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b5}ana']\n",
    "                    labelc1 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c1}ana']\n",
    "                    labelc2 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c2}ana']\n",
    "                    labelc3 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c3}ana']\n",
    "                    labelc4 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c4}ana']\n",
    "                    labelc5 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c5}ana']\n",
    "                    labeld = phrase.attrib['{www.dglab.uni-jena.de/vmf/d}ana']\n",
    "                    #13 Die Quelle wird aus dem Attribut 'id' der 'ganze'-Schleife extrahiert.\n",
    "                    quelle = ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "                    \n",
    "                    #14 Der Inhalt wird in Kleinbuchstaben umgewandelt und formatiert.\n",
    "                    inhalt = (phrase.text.lower().strip().replace('|','').replace(':','').replace(\"ä\",\"ae\")\n",
    "                              .replace(\"ü\",\"ue\").replace(\"ö\",\"oe\").replace(\"ß\",\"ss\").replace(\",\",\"\")\n",
    "                              .replace(\"«\",\"\").replace(\"»\",\"\").replace(\".\",\"\").replace('=',' ').replace(\";\",\"\")\n",
    "                              .replace('\"',\"\").replace(\"?\",\"\").replace(\"!\",\"\").replace(\"á\",\"a\").replace(\",\",\"\")\n",
    "                              .replace(\"\\t\",\" \").replace(\"'\",\"\").replace(\"‹\",\"\").replace(\"›\",\"\").replace(\"-\",\" \")\n",
    "                              .replace(\"'('\",\"\").replace(\"')'\",\"\").replace('>','').replace(\"    \",\" \")\n",
    "                              .replace(\"   \",\" \").replace(\"  \",\" \").replace('–','').replace('—','').replace('<','')\n",
    "                              .replace(\"Â\", \"A\").replace(\"ø\", \"oe\").replace('“','').replace('„','').replace('(','')\n",
    "                              .replace(')','').replace('*','').replace(\"\\n\",\"\\n\")\n",
    "                              .replace(\"'''\",\"\"))\n",
    "                    \n",
    "                    #15 Überprüfung, ob labela mit 'a' beginnt und nicht gleich 'N' ist.\n",
    "                    if labela.startswith('a') and labela != 'N':\n",
    "                        \n",
    "                            #16 Konstruktion des Datensatzes für das Märchen und Anhängen an die 'maerchen'-Zeichenkette.\n",
    "                            maerchen += (quelle+','+labela+','+labelb1+','+labelc1+','+labelb2+','+labelc2+','+\n",
    "                                         labelb3+','+labelc3+','+labelb4+','+labelc4+','+labelb5+','+labelc5+','+\n",
    "                                         labeld+','+inhalt+',0'+'\\n')\n",
    "                            \n",
    "with open(\"text.csv\", 'w', encoding='utf-8') as f:\n",
    "     #17 Schreiben der Kopfzeile in die CSV-Datei.\n",
    "    f.write('quelle,labela,labelb1,labelc1,labelb2,labelc2,labelb3,labelc3,labelb4,labelc4,labelb5,labelc5,labeld,inhalt,index_binar')\n",
    "    f.write('\\n')\n",
    "    #18 Schreiben der gesammelten Daten in die CSV-Datei.\n",
    "    f.write(maerchen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19 leere Zeichenketten, in der Daten für abcd1-5 gesammelt werden.\n",
    "abcd1 = \"\"\n",
    "abcd2 = \"\"\n",
    "abcd3 = \"\"\n",
    "abcd4 = \"\"\n",
    "abcd5 = \"\"\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "#20 Einlesen der CSV-Datei in ein DataFrame.\n",
    "df = pd.read_csv('text.csv', encoding='utf-8')\n",
    "\n",
    "#21 Hinzufügen von Daten an abcd1, abcd2, abcd3, abcd4 und abcd5.\n",
    "abcd1 += df.quelle+','+df.labela+':'+df.labelb1+':'+df.labelc1+':'+df.labeld+','+df.inhalt+',0'\n",
    "abcd2 += df.quelle+','+df.labela+':'+df.labelb2+':'+df.labelc2+':'+df.labeld+','+df.inhalt+',0'\n",
    "abcd3 += df.quelle+','+df.labela+':'+df.labelb3+':'+df.labelc3+':'+df.labeld+','+df.inhalt+',0'\n",
    "abcd4 += df.quelle+','+df.labela+':'+df.labelb4+':'+df.labelc4+':'+df.labeld+','+df.inhalt+',0'\n",
    "abcd5 += df.quelle+','+df.labela+':'+df.labelb5+':'+df.labelc5+':'+df.labeld+','+df.inhalt+',0'\n",
    "\n",
    "#22 Zusammenstellen der Daten aus abcd1 bis abcd5\n",
    "recorded = (abcd1 + '\\n' + abcd2 + '\\n' + abcd3 + '\\n' + abcd4 + '\\n' + abcd5 + '\\n')\n",
    "\n",
    "#23 Schreiben der aufgezeichneten Daten in eine CSV-Datei\n",
    "with open(\"text_aw.csv\", 'w', encoding='utf-8') as w:\n",
    "    w.write('quelle,index_string,inhalt,index_binar\\n')\n",
    "    w.write('000:ballast,ballast,ballast,0\\n')  #24 Schreiben einer Platzhalterzeile\n",
    "    w.write(\"\".join(recorded))  #25 Schreiben der aufgezeichneten Daten\n",
    "    \n",
    "\n",
    "mom = []  #26 Eine leere Liste zum Speichern der Daten\n",
    "\n",
    "#27 Lesen der CSV-Datei und Filtern von Zeilen mit ':N:' in der zweiten Spalte\n",
    "with open('text_aw.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        if ':N:' not in line[1]:  #28 Wenn ':N:' nicht in der zweiten Spalte enthalten ist\n",
    "            mom.append(line)  #29 Die Zeile der Liste mom hinzufügen\n",
    "            \n",
    "#30 Schreiben der gefilterten Daten in eine Textdatei.\n",
    "with open('text_ax.txt', 'wt', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(mom)  #26 Schreiben der Liste in die Datei\n",
    "    \n",
    "#31 Lesen der Textdatei und Formatieren der Daten\n",
    "with open('text_ax.txt', 'r', encoding='utf-8') as file:\n",
    "    filedata = file.read()\n",
    "filedata = (filedata.replace(']\",\"[', \"\\n\").replace('\"[', '').replace(']\"', '').replace(\" '\", \"\")\n",
    "            .replace(\"'\", \"\"))\n",
    "\n",
    "#32 Schreiben der formatierten Daten in eine CSV-Datei\n",
    "with open('text_ay.csv', 'w', encoding='utf-8') as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:24.190477Z",
     "start_time": "2024-01-25T21:11:24.156617Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "\n",
    "df = pd.read_csv('text_ay.csv', encoding='utf-8')  #33 Einlesen der Daten aus einer CSV-Datei in ein DataFrame\n",
    "\n",
    "#34 Eine Funktion zur Formatierung der Markupelemente eines Märchens\n",
    "def ep_format(ep_full):\n",
    "    return (ep_full.split(':'))[0]\n",
    "\n",
    "#35 Eine Funktion zur Formatierung des Typs eines Märchens.\n",
    "def ep_name_format(ep_full):\n",
    "    sublist = (ep_full)\n",
    "    name = \"\"\n",
    "    for strg in sublist:\n",
    "        name += strg\n",
    "    return name\n",
    "\n",
    "#36 Eine Funktion zum Vergleich von Quellen in einem DataFrame.\n",
    "def quellenvergleich(df, i1, i2):\n",
    "    return df.quelle[i1] == df.quelle[i2]\n",
    "\n",
    "#37 Eine Funktion zur Analyse von Abschnitten eines Märchens.\n",
    "def ast(gesep, df):\n",
    "    ep_tree = {}  #38 Ein leeres Dictionary zur Speicherung der Analyseergebnisse.\n",
    "    a_liste = []  #39 Eine leere Liste zur Speicherung von Startabschnitten.\n",
    "    z_liste = []  #40 Eine leere Liste zur Speicherung von Endabschnitten.\n",
    "    df_len = len(df.index_string)  #36 Die Anzahl der Zeilen im DataFrame.\n",
    "    for i, ep in enumerate(df.index_string):  #41 Iteration durch die 'Index-String' des DataFrames.\n",
    "        if gesep == ep:  #42 Wenn der aktuelle Abschnitt dem gesuchten Abschnitt entspricht.\n",
    "            if (i > 0) and (quellenvergleich(df, i, i - 1)):  #43 Wenn es einen vorherigen Abschnitt gibt und die Quellen übereinstimmen.\n",
    "                a = df.index_string[i - 1]  #44 Der vorherige Abschnitt wird als Startabschnitt betrachtet.\n",
    "            else:\n",
    "                a = 'Anf-' + ep_name_format(gesep)  #45 Ansonsten wird ein neuer Startabschnitt erstellt.\n",
    "            if (i < df_len - 1):  #46 Wenn es einen nächsten Abschnitt gibt.\n",
    "                if not (quellenvergleich(df, i, i + 1)):  #47 Wenn die Quellen des nächsten Abschnitts unterschiedlich sind.\n",
    "                    z = 'End-' + ep_name_format(gesep)  #48 Der aktuelle Abschnitt wird als Endabschnitt betrachtet.\n",
    "                else:\n",
    "                    z = df.index_string[i + 1]  #49 Ansonsten wird der nächste Abschnitt als Endabschnitt betrachtet.\n",
    "            else:\n",
    "                z = 'End-' + ep_name_format(gesep)  #50 Wenn es keinen nächsten Abschnitt gibt, wird ein neuer Endabschnitt erstellt.\n",
    "            a_liste.append(a)  #51 Startabschnitt wird der Liste hinzugefügt.\n",
    "            z_liste.append(z)  #52 Endabschnitt wird der Liste hinzugefügt.\n",
    "    return {gesep: [Counter(a_liste), Counter(z_liste)]}  #53 Rückgabe der Analyseergebnisse als Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:25.557996Z",
     "start_time": "2024-01-25T21:11:25.546033Z"
    }
   },
   "outputs": [],
   "source": [
    "def alle_aeste(gesep, df):\n",
    "    episoden_baeume = {}  #54 Ein leeres Dictionary zur Speicherung der Analyseergebnisse.\n",
    "    ep_list = []  #55 Eine leere Liste zur Speicherung von Episoden.\n",
    "    for ep_full in df.index_string:  #56 Iteration durch die 'Index-String' des DataFrames.\n",
    "        ep = ep_format(ep_full)  #57 Formatierung der Episode.\n",
    "        if gesep == ep:  #58 Wenn die gesuchte Episode gefunden wird.\n",
    "            ep_list.append(ep_full)  #59 Die Episode wird zur Liste hinzugefügt.\n",
    "    for ep in set(ep_list):  #60 Iteration durch jede einzigartige Episode in der Liste.\n",
    "        episoden_baeume.update(ast(ep, df))  #61 Die Analyseergebnisse für jede Episode werden dem Dictionary hinzugefügt.\n",
    "    return episoden_baeume  #62 Rückgabe des Dictionary mit den Analyseergebnissen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:29.915657Z",
     "start_time": "2024-01-25T21:11:29.903072Z"
    }
   },
   "outputs": [],
   "source": [
    "#63 Die Variable 'graph' wird mit den Analyseergebnissen für die Episode 'mZahl' initialisiert.\n",
    "graph = alle_aeste(mZahl, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:31.249124Z",
     "start_time": "2024-01-25T21:11:30.925952Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  #64 Importieren der matplotlib.pyplot-Bibliothek zur Visualisierung von Daten.\n",
    "import networkx as nx  #65 Importieren der networkx-Bibliothek zur Erstellung und Analyse von Netzwerken.\n",
    "#66 Eine Funktion zum Filtern von Daten für einen bestimmten Ast.\n",
    "def cutoff_ast_data(wuerzel, graph, nachbar_liste, cutoff=0):\n",
    "    vor = graph[wuerzel][0]  #67 Vorwärtsverbindungen des Astes.\n",
    "    zurueck = graph[wuerzel][1]  #68 Rückwärtsverbindungen des Astes.\n",
    "    nachbarn = vor.copy()  #69 Kopie der Vorwärtsverbindungen.\n",
    "    nachbarn.update(zurueck)  #70 Hinzufügen der Rückwärtsverbindungen.\n",
    "    for ast_name, ast_gewicht in sorted(nachbarn.items()):  #71 Iteration durch die Nachbarn des Astes.\n",
    "        if (ast_gewicht >= cutoff):  #72 Wenn das Gewicht größer oder gleich dem Cutoff-Wert ist.\n",
    "            nachbar_liste.append([ep_name_format(wuerzel),\n",
    "                                   ep_name_format(ast_name), ast_gewicht])  #73 Die Verbindung wird der Nachbarliste hinzugefügt.\n",
    "#74 Eine Funktion zum Filtern von Daten für den gesamten Graphen.\n",
    "def cutoff_graph_data(graph, cutoff=0):\n",
    "    nachbar_liste = []  #75 Eine leere Liste zur Speicherung der Nachbarn.\n",
    "    for i, (k, v) in enumerate(sorted(graph.items())):  #76 Iteration durch die Elemente des Graphen.\n",
    "        cutoff_ast_data(k, graph, nachbar_liste, cutoff)  #77 Filtern der Daten für jeden Ast.\n",
    "    neue_nachbar_liste = [[i, nachbar] for i, nachbar in enumerate(nachbar_liste)]  #78 Indexierung der Nachbarn.\n",
    "    return neue_nachbar_liste  #79 Rückgabe der gefilterten Nachbardaten.\n",
    "#80 Eine Funktion zur Aktualisierung der interaktiven Daten des Graphen.\n",
    "def interactive_graph_data(graph_data, loesch_index, gew_dict):\n",
    "    for k, v in gew_dict.items():  #81 Iteration durch die Gewichts-Daten.\n",
    "        graph_data[k][1][2] = v  #82 Aktualisieren der Gewichts-Daten.\n",
    "    neue_nachbar_liste = [[i, nachbar[1]] for i,\n",
    "                          nachbar in enumerate(graph_data) if i not in loesch_index]  #83 Filtern der Daten.\n",
    "    return neue_nachbar_liste  #84 Rückgabe der aktualisierten Daten.\n",
    "\n",
    "#85 Eine Funktion zum Aufbau des Graphen aus den Daten.\n",
    "def graph_bauer(graph_data):\n",
    "    G = nx.DiGraph()  #86 Initialisierung eines gerichteten Graphen.\n",
    "    w_liste = []  #87 Eine leere Liste zur Speicherung der Gewichts-Daten.\n",
    "    for el in graph_data:  #88 Iteration durch die Elemente der Graphendaten.\n",
    "        n1 = el[1][0]  #89 Der Ausgangsknoten der Verbindung.\n",
    "        n2 = el[1][1]  #90 Der Zielknoten der Verbindung.\n",
    "        w = el[1][2]  #91 Das Gewicht der Verbindung.\n",
    "        w_liste.append(w)  #92 Hinzufügen des Gewichts zur Liste.\n",
    "        #93 Hinzufügen der Verbindung und der Knoten zum Graphen.\n",
    "        G.add_edge(n1, n2, weight=w, title=w)\n",
    "        G.add_edge(n1, n2, weight=w, title=w)\n",
    "        G.add_node(n1, title=n1, size=15)\n",
    "        G.add_node(n2, title=n2, size=15)\n",
    "    return G, w_liste  #94 Rückgabe des Graphen und der Gewichtsliste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:32.130557Z",
     "start_time": "2024-01-25T21:11:32.122432Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#95 Filtern der Graphendaten basierend auf der Häufigkeit.\n",
    "auto_graph = cutoff_graph_data(graph, haeufigkeit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:12:53.897428Z",
     "start_time": "2024-01-25T21:12:53.677815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network \n",
    "#96 Erstellen des Graphen und der Gewichtsliste aus den Graphendaten.\n",
    "G, W = graph_bauer(auto_graph)\n",
    "#97 Erstellen einer Network-Instanz für die Visualisierung des Graphen.\n",
    "nt = Network(notebook=True,  #98 Das Netzwerk wird im Jupyter Notebook angezeigt.\n",
    "             height='900px',  #99 Höhe des Netzwerks.\n",
    "             width='100%',  #100 Breite des Netzwerks.\n",
    "             directed=False,  #101 Der Graph ist ungerichtet.\n",
    "             bgcolor='#ffffff',  #102 Hintergrundfarbe des Netzwerks.\n",
    "             font_color=False,  #103 Die Farbe der Schrift im Netzwerk wird automatisch festgelegt.\n",
    "             layout=None,  #104 Die Layout-Eigenschaft wird nicht gesetzt (standardmäßig wird ein Fruchterman-Reingold-Layout verwendet).\n",
    "             heading='',  #105 Ein leerer Titel für das Netzwerk.\n",
    "             cdn_resources='local')  #106 Die Ressourcen werden lokal geladen (ohne Internetverbindung).\n",
    "#107 Fügen Sie die Knoten und Kanten des Graphen zur Netzwerkinstanz hinzu.\n",
    "nt.from_nx(G)\n",
    "#108 Anzeigen des Netzwerks im Jupyter Notebook.\n",
    "#nt.show('nx.html')  #109 Die Visualisierung wird in einer HTML-Datei gespeichert und im Notebook angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T20:53:45.643261Z",
     "start_time": "2024-01-25T20:53:45.629312Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv  \n",
    "import numpy as np \n",
    "#110 Eine Funktion zur Überprüfung, ob ein Nachbar in einen Knoten einbezogen werden kann.\n",
    "def neighbour_is_includable(node, neighbour):\n",
    "    designation = \":\".join(node.split(\":\")[0:1])  #111 Extrahieren der Bezeichnung des Knotens.\n",
    "    return neighbour.startswith(designation)  #112 Rückgabe, ob der Nachbar in den Knoten einbezogen werden kann.\n",
    "#113 Eine Funktion zur Bereinigung der Kanten basierend auf der Einbeziehbarkeit.\n",
    "def pruned_edges(node, neighbours):\n",
    "    return [neighbor for neighbor in neighbours if neighbour_is_includable(node, neighbor)]\n",
    "#114 Eine Funktion zur Erstellung eines bereinigten Graphen.\n",
    "def make_pruned_graph(graph):\n",
    "    pruned_graph = {}\n",
    "    for node, (incoming, outgoing) in graph.items():\n",
    "        pruned_incoming = pruned_edges(node, incoming)\n",
    "        pruned_outgoing = pruned_edges(node, outgoing)\n",
    "        pruned_graph[node] = (pruned_incoming, pruned_outgoing)\n",
    "    return pruned_graph\n",
    "#115 Eine Funktion zur Erstellung eines gerichteten Rückgrat-Graphen.\n",
    "def make_backbone_di_graph(pruned_graph):\n",
    "    new_DiGraph = nx.DiGraph()\n",
    "    for node, (incoming, outgoing) in pruned_graph.items():\n",
    "        for in_node in incoming:\n",
    "            new_DiGraph.add_edge(in_node, node)\n",
    "        for out_node in outgoing:\n",
    "            new_DiGraph.add_edge(node, out_node)\n",
    "    return new_DiGraph\n",
    "#116 Eine Funktion zur Berechnung der kürzesten Pfade mit Vorzeichen.\n",
    "def signed_shortest_path_length(G, source, target):\n",
    "    try:\n",
    "        pl = nx.dijkstra_path_length(G, source=source, target=target)\n",
    "    except nx.NodeNotFound:\n",
    "        pl = np.Inf\n",
    "    except nx.NetworkXNoPath:\n",
    "        try:\n",
    "            pl = - nx.dijkstra_path_length(G, source=target, target=source)\n",
    "        except nx.NodeNotFound:\n",
    "            pl = np.Inf\n",
    "        except nx.NetworkXNoPath:\n",
    "            pl = np.Inf\n",
    "    return pl\n",
    "#117 Eine Funktion zur Erstellung von Distanzdaten für Hauptknoten.\n",
    "def create_main_node_distances(start_node, pruned_graph, graph, nx_graph):\n",
    "    distances = { key:[] for key in graph}\n",
    "    backbone_di_graph= make_backbone_di_graph(pruned_graph)\n",
    "    for node in pruned_graph:\n",
    "        distances[node] = {signed_shortest_path_length(backbone_di_graph, start_node, node)}\n",
    "    return distances\n",
    "#118 Eine Funktion zum Hinzufügen von Distanzdaten für Unter- bzw. Nebenknoten.\n",
    "def add_sub_node_distances(node, sub_nodes, pruned_graph, distances, d):\n",
    "    for sub_node in sub_nodes:\n",
    "        if sub_node not in pruned_graph.keys():\n",
    "            if sub_node not in distances:\n",
    "                distances[sub_node] = set()\n",
    "            new_dists = {dist + d for dist in distances[node]}\n",
    "            distances[sub_node].update(new_dists)\n",
    "#119 Eine Funktion zur Erstellung eines Distanz-Dictionarys.\n",
    "def create_distance_dict(start_node, graph, G):\n",
    "    pruned_graph = make_pruned_graph(graph)\n",
    "    distances = create_main_node_distances(start_node, pruned_graph, graph, G)\n",
    "    for node, (incoming, outgoing) in graph.items():\n",
    "        add_sub_node_distances(node, incoming, pruned_graph, distances, -1)\n",
    "        add_sub_node_distances(node, outgoing, pruned_graph, distances, 1)\n",
    "    return distances\n",
    "#120 Startknoten für die Berechnung der Distanzen.\n",
    "start_node = mWert\n",
    "#121 Erstellen der Distanzdaten.\n",
    "distances = create_distance_dict(start_node, graph, G)\n",
    "#122 Sortieren der Distanzdaten nach den minimalen Distanzen.\n",
    "sorted_keys = sorted(distances, key=lambda x: min(distances[x]))\n",
    "sorted_distances = {key: distances[key] for key in sorted_keys}\n",
    "#123 Konvertierung der Distanzdaten in eine Zeichenfolge für den HTML-Output.\n",
    "msia=\"\"\n",
    "tai = []\n",
    "for k, v in sorted_distances.items():\n",
    "    sia=(f\"{k} {v}\")\n",
    "    msia+=sia+'<br>'\n",
    "    tai.append(sia)\n",
    "    #print(sia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#124 Pfad zur CSV-Datei\n",
    "csv_file_path = 'output_1.csv'\n",
    "#125 Schreibe die Daten in die CSV-Datei\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')  \n",
    "    #126 Schreibe die Überschrift (Header) in die CSV-Datei\n",
    "    writer.writerow(['Data'])\n",
    "    #127 Schreibe die Zeilen in die CSV-Datei\n",
    "    for data in tai:\n",
    "        writer.writerow([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#128 Diese Funktion erstellt eine Menge aus den ausgewählten Knoten basierend auf den Kanten im Graphen.\n",
    "def make_set_of_chosen_vertices(graph_edge_data):\n",
    "    chosen_vertices = set()  #129 Initialisierung einer leeren Menge für ausgewählte Knoten\n",
    "    for sub_list in graph_edge_data:  #130 Iteration durch die Kanten im Graphen\n",
    "        sub_sub_list = sub_list[1]  #131 Die Kanteninformationen befinden sich in der zweiten Unterliste\n",
    "        chosen_vertices.add(sub_sub_list[0])  #132 Hinzufügen des ersten Knotens der Kante zur Menge ausgewählter Knoten\n",
    "        chosen_vertices.add(sub_sub_list[1])  #133 Hinzufügen des zweiten Knotens der Kante zur Menge ausgewählter Knoten\n",
    "    return chosen_vertices  #134 Rückgabe der Menge ausgewählter Knoten\n",
    "\n",
    "dat = []  #135 Initialisierung einer leeren Liste 'dat' für Daten\n",
    "\n",
    "#136 'graph_data' enthält die Informationen über die Kanten im Graphen, basierend auf einer bestimmten Häufigkeitsschwelle ('haeufigkeit')\n",
    "graph_data = cutoff_graph_data(graph, haeufigkeit)\n",
    "\n",
    "#137 Die ausgewählten Knoten werden aus der Menge ausgewählt und sortiert\n",
    "chosen_vertices = list(make_set_of_chosen_vertices(graph_data))  \n",
    "chosen_vertices.sort()  \n",
    "\n",
    "#138 Iteration durch die ausgewählten Knoten\n",
    "for vertex_name in chosen_vertices:\n",
    "    dat.append(vertex_name)  #134 Hinzufügen des Knotennamens zur Liste 'dat'\n",
    "csv_file_path = 'output_2.csv'\n",
    "#139 Schreibe die Daten in die CSV-Datei\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')    \n",
    "    #140 Schreibe die Überschrift (Header) in die CSV-Datei\n",
    "    writer.writerow(['Data'])\n",
    "    #141 Schreibe die Zeilen in die CSV-Datei\n",
    "    for data in dat:\n",
    "        writer.writerow([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "Anf-a551:h:Krankheit:rHH {-1}\n",
      "a551:h:Krankheit:rHH {0}\n",
      "a551:F:Anregen_zu_Beauftragungen:rHH_rVB {1}\n",
      "a551:F:Werben_um_den_Auftrag:rHH_fHD {2}\n",
      "a551:F:Heilmittel_beschaffen:rHH_fHD {2}\n",
      "a551:f:Anlocken:fHD {3}\n",
      "a551:Ff:Handlungsanweisung_Wegweisung_mit_Optionen:rZM_fHD {3}\n",
      "a551:f:Anlocken:fHD_fVB {3}\n",
      "a551:Hh:Ausrüsten:rHD_fHD_fZM {3}\n",
      "a551:f:Festnahme_bzw_Sperren:fHD_fVB {3}\n",
      "a551:h:Respektlosigkeit:rHD_fHD_fZM {4}\n",
      "a551:h:Anlocken_nachgehen:fHD {4}\n",
      "a551:F:Werben_um_den_Auftrag:rHD_rHH {4}\n",
      "a551:Hh:Wegweisung_mit_Optionen_nachgehen:rZM_fHD {4}\n",
      "a551:h:Anlocken_nachgehen:fHD_fVB {4}\n",
      "a551:h:Sich_abseilen_lassen:rHD_fHD {5}\n",
      "a551:f:Anlocken:rHD_fVB {5}\n",
      "a551:H:Anlocken_nachgehen:rHD_fVB {6}\n",
      "a551:Hh:Ausrüsten:rHD {6}\n",
      "a551:H:Bestrafung:fHD {7}\n",
      "a551:Hh:Überweisung_an_anderen_Stifter_oder_Helfer:rHD_rST {7}\n",
      "a551:H:Reittier_erhalten:rHD_rST {7}\n",
      "a551:H:Reittier_erhalten:rHD {7}\n",
      "a551:F:Gastgeberschaft_sichern:rHD_rST {8}\n",
      "a551:H:Heiraten:rHD_rHH_rBZ {8}\n",
      "a551:F:Heilmittel_beschaffen:rHD_rST {8}\n",
      "a551:H:Gastgeberschaft_sichern:rHD_rST {8}\n",
      "a551:H:Versprechen_von_Hilfe_erhalten:rHD_rST {9}\n",
      "a551:H:Besitzer_des_Objektes_ergreifen:rHD_rBZ {9}\n",
      "a551:H:Besitzer_des_Objektes_ergreifen:rHD_rBZ_rZO {9}\n",
      "a551:F:Seltenen_Gegenstand_beschaffen:rHH_rVB {9}\n",
      "End-a551:H:Heiraten:rHD_rHH_rBZ {9}\n",
      "a551:F:Markieren:rHD_rBZ {10}\n",
      "a551:F:Markieren:rHD_rBZ_rZO {10}\n",
      "a551:h:Kontakt_abbrechen:rHD_rBZ_rZO {11}\n",
      "a551:h:Kontakt_abbrechen:rHD_rBZ {12}\n",
      "a551:H:Flug_zeugendes_Transportmittel_erhalten:rHD_rST_rZM {12}\n",
      "a551:Hh:Vergeltung_Angst_um_Angst:rHD_rHF {12}\n",
      "a551:H:Zurückgreifen:rHD_rST_rZM {13}\n",
      "a551:f:Missetat_planen:rZO_fHD {13}\n",
      "a551:F:Flucht:rHD_rST {13}\n",
      "a551:F:Zurückgreifen:rHD_rST_rZM {14}\n",
      "a551:H:Vergütung_Gegenleistung_um_Hilfe:rHD_rST_rZM {14}\n",
      "a551:Hh:Heilmittel_beschaffen:rHH_rZO_fHD {14}\n",
      "a551:h:Missetat_Aneignen:rZO_fHD {14}\n",
      "a551:H:Verfolgung_hindern:rST_rBZ {14}\n",
      "a551:F:Verfolgung_hindern:rST_rBZ {14}\n",
      "a551:Hh:Krankheit_beheben:rHH_rZO_fHD {15}\n",
      "a551:H:Zaubermittel_erhalten:rHD_rST_rZM {15}\n",
      "a551:H:Markieren_erkennen:rBZ {16}\n",
      "a551:h:Respektlosigkeit:rHD_fHD {17}\n",
      "a551:F:Kontakt_wiederherstellen:rBZ {17}\n",
      "a551:h:Identität_testen:rBZ_fHD {18}\n",
      "a551:h:Bestrafung:rBZ_fHD {19}\n",
      "a551:F:Kontakt_wiederherstellen:rHH_rVB_rBZ {20}\n"
     ]
    }
   ],
   "source": [
    "#142 Liste a\n",
    "sia_a=[]\n",
    "with open('output_1.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f) \n",
    "    for line in reader:\n",
    "            sia_a.append(line)\n",
    "#143 Liste b\n",
    "sia_b=[]         \n",
    "with open('output_2.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f) \n",
    "    for line in reader:\n",
    "            sia_b.append(line)\n",
    "#144 Liste c\n",
    "sia_c=[]\n",
    "#145 Iteriere durch Liste a\n",
    "for element_a in sia_a:\n",
    "    #146 Extrahiere den linken String aus dem ersten Element in Liste a\n",
    "    left_string_a = element_a[0].split(' ')[0]\n",
    "\n",
    "    #147 Überprüfe, ob der linke String aus Liste a in Liste b vorhanden ist\n",
    "    if any(left_string_a in element_b[0] for element_b in sia_b):\n",
    "        #148 Wenn ja, füge das aktuelle Element aus Liste a zu Liste c hinzu\n",
    "        sia_c.append(element_a[0])\n",
    "#149 Ausgabe der generierten Liste c\n",
    "for element_c in sia_c:\n",
    "    print(element_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typ: a551\n",
      "Motiv: a551:h:Krankheit:rHH\n",
      "Häufigkeit: 2\n",
      "nx.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"900px\"\n",
       "            src=\"nx.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x175cc670410>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt.from_nx(G)  #150 Konvertiere den NetworkX-Graphen G in ein pyvis-Network-Objekt\n",
    "print(f'Typ: {mZahl}\\nMotiv: {mWert}\\nHäufigkeit: {haeufigkeit}')  #148 Gib Informationen über den Graphen aus\n",
    "nt.show('nx.html')  #149 Speichere die Visualisierung als HTML-Datei und zeige sie an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
