{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswertung - a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README\n",
    "\n",
    "Der Code visualisiert die Kombination vonT ypen innerhalb eines Märchenrepertoire.\n",
    "\n",
    "Motive eines Typs wird durch das Attribut a dargestellt 1-Tupel (a=Typnummer).\n",
    "Anpassbare Zeilen:\n",
    "\n",
    "(#2 und #27) Pfad zu der Inputdatei.\n",
    "\n",
    "(#6 und 30) Der Attributwert bestimmt die Herkunft der zu analysierenden Textgruppe (des Repertoires). Die Filter können mit den 'or' und 'and' Operatoren ergänzt werden, z. B.:  \n",
    "\n",
    "if ('deu' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "\n",
    "    or 'ita' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']): \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=\"\"  #1 Eine leere Zeichenfolge wird initialisiert.\n",
    "import xml.etree.ElementTree as ET\n",
    "root_node = ET.parse('Textkorpus.xml').getroot()  #2 Die Wurzel des XML-Baums wird aus der Datei \"Textkorpus.xml\" gelesen und zugewiesen.\n",
    "never_saved = True  #3 Eine boolsche Variable never_saved wird auf True gesetzt.\n",
    "schema_dict = dict()  #4 Ein leeres Dictionary wird initialisiert.\n",
    "for ganze in root_node.findall(\".//{http://www.tei-c.org/ns/1.0}text\"):  #5 Eine Schleife durchläuft alle Elemente mit dem Tag 'text'.\n",
    "    if '' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']:  #6 Überprüft, ob ein leerer Wert in den Attributen vorhanden ist.\n",
    "        for body in ganze.findall(\".//{http://www.tei-c.org/ns/1.0}body\"):  #7 Eine Schleife durchläuft alle Elemente mit dem Tag 'body'.\n",
    "            for absatz in body.findall(\".//{http://www.tei-c.org/ns/1.0}p\"):  #8 Eine Schleife durchläuft alle Elemente mit dem Tag 'p'.\n",
    "                for phrase in absatz.findall(\".//{http://www.tei-c.org/ns/1.0}seg\"):  #9 Eine Schleife durchläuft alle Elemente mit dem Tag 'seg'.\n",
    "                    labela = phrase.attrib['{www.dglab.uni-jena.de/vmf/a}ana']  #10 Der Wert des Attributs '{www.dglab.uni-jena.de/vmf/a}ana' wird zugewiesen.\n",
    "                    if labela.startswith('a'):  #11 Überprüft, ob der Wert des Attributs mit 'a' beginnt.\n",
    "                        combined_label = labela  #12 Der Wert des Attributs wird zugewiesen.\n",
    "                        if labela not in schema_dict:  #13 Überprüft, ob der Wert des Attributs nicht im Dictionary enthalten ist.\n",
    "                            schema_dict[labela] = {combined_label}  #14 Ein neuer Eintrag wird im Dictionary erstellt.\n",
    "                        else:\n",
    "                            schema_dict[labela].add(combined_label)  #15 Der Wert wird dem entsprechenden Eintrag im Dictionary hinzugefügt.\n",
    "for k, v in sorted(schema_dict.items()):  #16 Eine Schleife durchläuft die Elemente des sortierten Dictionarys.\n",
    "    schema += f'graph.update(alle_aeste(\"{k}\", df))\\n'  #17 Ein String wird zur Variablen schema hinzugefügt.\n",
    "with open(\"TypGraph.txt\", 'w', encoding='utf-8') as f:  #18 Eine Datei mit dem Namen 'TypGraph.txt' wird im Schreibmodus geöffnet.\n",
    "    f.write(schema)  #19 Der Inhalt der Variable schema wird in die Datei geschrieben.\n",
    "#print(schema)  #20 Dieser Code ist auskommentiert.\n",
    "def graph_update():  #21 Eine Funktion graph_update wird definiert.\n",
    "    with open(\"TypGraph.txt\", \"r\") as datei:  #22 Die Datei 'TypGraph.txt' wird im Lesemodus geöffnet.\n",
    "        zusatz_code = datei.read()  #23 Der Inhalt der Datei wird in die Variable zusatz_code gelesen.\n",
    "    exec(zusatz_code)  #24 Der Python-Code in zusatz_code wird ausgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:22.943093Z",
     "start_time": "2024-01-25T21:11:21.693040Z"
    }
   },
   "outputs": [],
   "source": [
    "maerchen = \"\"  #25 Eine leere Zeichenkette, in der Daten für Märchen gesammelt werden.\n",
    "import xml.etree.ElementTree as ET  #26 Importieren der ElementTree-Bibliothek zum Parsen von XML.\n",
    "root_node = ET.parse('Textkorpus.xml').getroot()  #27 Parsen der XML-Datei und Zugriff auf das Wurzelelement.\n",
    "never_saved = True  #28 Ein boolean-Wert, der angibt, ob Daten bereits gespeichert wurden oder nicht.\n",
    "#29 Iteration durch jedes 'text'-Element in der XML-Datei.\n",
    "for ganze in root_node.findall(\".//{http://www.tei-c.org/ns/1.0}text\"):\n",
    "    #30 Überprüfung, ob das Attribut 'deu' in der 'id'-Eigenschaft des 'text'-Elements vorhanden ist.\n",
    "    if ('' in ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']):\n",
    "        #31 Iteration durch jeden Absatz im 'body' des 'text'-Elements.\n",
    "        for body in ganze.findall(\".//{http://www.tei-c.org/ns/1.0}body\"):\n",
    "            for absatz in body.findall(\".//{http://www.tei-c.org/ns/1.0}p\"):\n",
    "                #32 Iteration durch jede 'seg'-Phrase im Absatz.\n",
    "                for phrase in absatz.findall(\".//{http://www.tei-c.org/ns/1.0}seg\"):\n",
    "                    #33 Extrahieren von Labels und Inhalten aus den Attributen und dem Text der Phrase.\n",
    "                    labela = phrase.attrib['{www.dglab.uni-jena.de/vmf/a}ana']\n",
    "                    labelb1 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b1}ana']\n",
    "                    labelb2 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b2}ana']\n",
    "                    labelb3 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b3}ana']\n",
    "                    labelb4 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b4}ana']\n",
    "                    labelb5 = phrase.attrib['{www.dglab.uni-jena.de/vmf/b5}ana']\n",
    "                    labelc1 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c1}ana']\n",
    "                    labelc2 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c2}ana']\n",
    "                    labelc3 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c3}ana']\n",
    "                    labelc4 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c4}ana']\n",
    "                    labelc5 = phrase.attrib['{www.dglab.uni-jena.de/vmf/c5}ana']\n",
    "                    labeld = phrase.attrib['{www.dglab.uni-jena.de/vmf/d}ana']\n",
    "                    #34 Die Quelle wird aus dem Attribut 'id' der 'ganze'-Schleife extrahiert.\n",
    "                    quelle = ganze.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "                    #35 Der Inhalt wird in Kleinbuchstaben umgewandelt und formatiert.\n",
    "                    inhalt = (phrase.text.lower().strip().replace('|','').replace(':','').replace(\"ä\",\"ae\")\n",
    "                              .replace(\"ü\",\"ue\").replace(\"ö\",\"oe\").replace(\"ß\",\"ss\").replace(\",\",\"\")\n",
    "                              .replace(\"«\",\"\").replace(\"»\",\"\").replace(\".\",\"\").replace('=',' ').replace(\";\",\"\")\n",
    "                              .replace('\"',\"\").replace(\"?\",\"\").replace(\"!\",\"\").replace(\"á\",\"a\").replace(\",\",\"\")\n",
    "                              .replace(\"\\t\",\" \").replace(\"'\",\"\").replace(\"‹\",\"\").replace(\"›\",\"\").replace(\"-\",\" \")\n",
    "                              .replace(\"'('\",\"\").replace(\"')'\",\"\").replace('>','').replace(\"    \",\" \")\n",
    "                              .replace(\"   \",\" \").replace(\"  \",\" \").replace('–','').replace('—','').replace('<','')\n",
    "                              .replace(\"Â\", \"A\").replace(\"ø\", \"oe\").replace('“','').replace('„','').replace('(','')\n",
    "                              .replace(')','').replace('*','').replace(\"\\n\",\"\\n\")\n",
    "                              .replace(\"'''\",\"\"))\n",
    "                    #36 Überprüfung, ob labela mit 'a' beginnt und nicht gleich 'N' ist.\n",
    "                    if labela.startswith('a') and labela != 'N':\n",
    "                            #37 Konstruktion des Datensatzes für das Märchen und Anhängen an die 'maerchen'-Zeichenkette.\n",
    "                            maerchen += (quelle+','+labela+','+labelb1+','+labelc1+','+labelb2+','+labelc2+','+\n",
    "                                         labelb3+','+labelc3+','+labelb4+','+labelc4+','+labelb5+','+labelc5+','+\n",
    "                                         labeld+','+inhalt+',0'+'\\n')                       \n",
    "with open(\"text.csv\", 'w', encoding='utf-8') as f:\n",
    "     #38 Schreiben der Kopfzeile in die CSV-Datei.\n",
    "    f.write('quelle,labela,labelb1,labelc1,labelb2,labelc2,labelb3,labelc3,labelb4,labelc4,labelb5,labelc5,labeld,inhalt,index_binar')\n",
    "    f.write('\\n')\n",
    "    #39 Schreiben der gesammelten Daten in die CSV-Datei.\n",
    "    f.write(maerchen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:23.259948Z",
     "start_time": "2024-01-25T21:11:22.878454Z"
    }
   },
   "outputs": [],
   "source": [
    "#40 leere Zeichenketten, in der Daten für abcd1-5 gesammelt werden.\n",
    "abcd1 = \"\"\n",
    "abcd2 = \"\"\n",
    "abcd3 = \"\"\n",
    "abcd4 = \"\"\n",
    "abcd5 = \"\"\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "#41 Einlesen der CSV-Datei in ein DataFrame.\n",
    "df = pd.read_csv('text.csv', encoding='utf-8')\n",
    "#42 Hinzufügen von Daten an abcd1, abcd2, abcd3, abcd4 und abcd5.\n",
    "abcd1 += df.quelle+','+df.labela+':'+df.labelb1+':'+df.labelc1+':'+df.labeld+','+df.inhalt+',0'\n",
    "abcd2 += df.quelle+','+df.labela+':'+df.labelb2+':'+df.labelc2+':'+df.labeld+','+df.inhalt+',0'\n",
    "abcd3 += df.quelle+','+df.labela+':'+df.labelb3+':'+df.labelc3+':'+df.labeld+','+df.inhalt+',0'\n",
    "abcd4 += df.quelle+','+df.labela+':'+df.labelb4+':'+df.labelc4+':'+df.labeld+','+df.inhalt+',0'\n",
    "abcd5 += df.quelle+','+df.labela+':'+df.labelb5+':'+df.labelc5+':'+df.labeld+','+df.inhalt+',0'\n",
    "#43 Zusammenstellen der Daten aus abcd1 bis abcd5.\n",
    "recorded = (abcd1 + '\\n' + abcd2 + '\\n' + abcd3 + '\\n' + abcd4 + '\\n' + abcd5 + '\\n')\n",
    "#44 Schreiben der aufgezeichneten Daten in eine CSV-Datei.\n",
    "with open(\"text_aw.csv\", 'w', encoding='utf-8') as w:\n",
    "    w.write('quelle,index_string,inhalt,index_binar\\n')\n",
    "    w.write('000:ballast,ballast,ballast,0\\n')  #45 Schreiben einer Platzhalterzeile.\n",
    "    w.write(\"\".join(recorded))  #46 Schreiben der aufgezeichneten Daten.\n",
    "    w.close()\n",
    "import csv\n",
    "mom = []  #47 Eine leere Liste zum Speichern der Daten.\n",
    "\n",
    "#48 Lesen der CSV-Datei und Filtern von Zeilen mit ':N:' in der zweiten Spalte.\n",
    "with open('text_aw.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        if ':N:' not in line[1]:  #49 Wenn ':N:' nicht in der zweiten Spalte enthalten ist.\n",
    "            mom.append(line)  #50 Die Zeile der Liste mom hinzufügen.\n",
    "#51 Schreiben der gefilterten Daten in eine Textdatei.\n",
    "with open('text_ax.txt', 'wt', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(mom)  # Schreiben der Liste in die Datei.\n",
    "#52 Lesen der Textdatei und Formatieren der Daten.\n",
    "with open('text_ax.txt', 'r', encoding='utf-8') as file:\n",
    "    filedata = file.read()\n",
    "filedata = (filedata.replace(']\",\"[', \"\\n\").replace('\"[', '').replace(']\"', '').replace(\" '\", \"\")\n",
    "            .replace(\"'\", \"\"))\n",
    "#53 Schreiben der formatierten Daten in eine CSV-Datei.\n",
    "with open('text_ay.csv', 'w', encoding='utf-8') as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "#54 Lesen einer CSV-Datei mit dem Namen 'text_ay.csv' in ein DataFrame mit dem Namen df\n",
    "df = pd.read_csv('text_ay.csv', encoding='utf-8')\n",
    "#55 Definition einer Funktion, um ein spezifisches Format aus einem String zu extrahieren, der eine Episode repräsentiert\n",
    "def ep_format(ep_full):\n",
    "    return (ep_full.split(':'))[0]\n",
    "#56 Definition einer Funktion, um den Namen einer Episode zu formatieren\n",
    "def ep_name_format(ep_full):\n",
    "    sublist = (ep_full).split(':')[0:1]  #57 Extrahieren des ersten Teils des Episoden-Strings\n",
    "    name = \"\"\n",
    "    for strg in sublist:\n",
    "        name += strg  #58 Zusammensetzen der Teile des Episoden-Strings\n",
    "    return name\n",
    "#59 Definition einer Funktion, um die Quellen zweier Indizes im DataFrame zu vergleichen\n",
    "def quellenvergleich(df, i1, i2):\n",
    "    return df.quelle[i1] == df.quelle[i2]\n",
    "#60 Definition einer Funktion, um Segmente (Episoden) im DataFrame zu analysieren\n",
    "def ast(gesep, df):\n",
    "    ep_tree = {}  #61 Initialisierung eines leeren Dictionarys zur Speicherung von Episodeninformationen\n",
    "    a_liste = []  #62 Initialisierung einer leeren Liste zur Speicherung von Startpunkten der Segmente\n",
    "    z_liste = []  #63 Initialisierung einer leeren Liste zur Speicherung von Endpunkten der Segmente\n",
    "    df_len = len(df.index_string)  #64 Ermitteln der Länge der Spalte 'index_string' im DataFrame\n",
    "    #65 Schleife durch den DataFrame, um Segmente zu analysieren\n",
    "    for i, ep in enumerate(df.index_string):\n",
    "        if gesep == ep:  #66 Überprüfen, ob die aktuelle Episode der angegebenen entspricht\n",
    "            #67 Bestimmung des Startpunkts des Segments\n",
    "            if (i > 0) and (quellenvergleich(df, i, i - 1)):\n",
    "                a = df.index_string[i - 1]\n",
    "            else:\n",
    "                a = 'Anf-' + ep_name_format(gesep)\n",
    "            #68 Bestimmung des Endpunkts des Segments\n",
    "            if (i < df_len - 1):\n",
    "                if not (quellenvergleich(df, i, i + 1)):\n",
    "                    z = 'End-' + ep_name_format(gesep)\n",
    "                else:\n",
    "                    z = df.index_string[i + 1]\n",
    "            else:\n",
    "                z = 'End-' + ep_name_format(gesep)\n",
    "            #69 Hinzufügen der Start- und Endpunkte zu ihren jeweiligen Listen\n",
    "            a_liste.append(a)\n",
    "            z_liste.append(z)\n",
    "    #70 Konstruktion eines Dictionarys, das die Start- und Endpunkte des Segments enthält\n",
    "    return {gesep: [Counter(a_liste), Counter(z_liste)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:25.557996Z",
     "start_time": "2024-01-25T21:11:25.546033Z"
    }
   },
   "outputs": [],
   "source": [
    "def alle_aeste(gesep, df):\n",
    "    episoden_baeume = {}  #71 Ein leeres Dictionary zur Speicherung der Analyseergebnisse.\n",
    "    ep_list = []  #72 Eine leere Liste zur Speicherung von Episoden.\n",
    "    for ep_full in df.index_string:  #73 Iteration durch die 'Index-String' des DataFrames.\n",
    "        ep = ep_format(ep_full)  #74 Formatierung der Episode.\n",
    "        if gesep == ep:  #75 Wenn die gesuchte Episode gefunden wird.\n",
    "            ep_list.append(ep_full)  #76 Die Episode wird zur Liste hinzugefügt.\n",
    "    for ep in set(ep_list):  #77 Iteration durch jede einzigartige Episode in der Liste.\n",
    "        episoden_baeume.update(ast(ep, df))  #78 Die Analyseergebnisse für jede Episode werden dem Dictionary hinzugefügt.\n",
    "    return episoden_baeume  #79 Rückgabe des Dictionary mit den Analyseergebnissen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:29.915657Z",
     "start_time": "2024-01-25T21:11:29.903072Z"
    }
   },
   "outputs": [],
   "source": [
    "#80 Die Variable 'graph' wird mit den Analyseergebnissen für die Episode 'mZahl' initialisiert.\n",
    "graph = alle_aeste('', df)\n",
    "#81 Die Funktion graph_update wird aktiviert\n",
    "graph_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx \n",
    "#82 Eine Funktion zum Ausschneiden von Astdaten basierend auf einem Schwellenwert\n",
    "def cutoff_ast_data(wuerzel, graph, nachbar_liste, cutoff=0):\n",
    "    vor = graph[wuerzel][0]\n",
    "    zurueck = graph[wuerzel][1]\n",
    "    nachbarn = vor.copy()\n",
    "    nachbarn.update(zurueck)\n",
    "    for ast_name, ast_gewicht in sorted(nachbarn.items()):\n",
    "        if (ast_gewicht >= cutoff):\n",
    "             nachbar_liste.append([ep_name_format(wuerzel), \n",
    "                                   ep_name_format(ast_name), ast_gewicht])  \n",
    "#83 Eine Funktion zum Ausschneiden von Graphdaten basierend auf einem Schwellenwert\n",
    "def cutoff_graph_data(graph, cutoff=0):\n",
    "    nachbar_liste = []\n",
    "    for i, (k, v) in enumerate(sorted(graph.items())):\n",
    "        cutoff_ast_data(k, graph, nachbar_liste, cutoff)\n",
    "    neue_nachbar_liste = [[i, nachbar] for i, nachbar in enumerate(nachbar_liste)]\n",
    "    return neue_nachbar_liste\n",
    "#84 Eine Funktion zur Interaktion mit Graphdaten basierend auf einem Löschindex und einem Gewichts-Dictionary\n",
    "def interactive_graph_data(graph_data, loesch_index, gew_dict):\n",
    "    for k, v in gew_dict.items():\n",
    "        graph_data[k][1][2] = v\n",
    "    neue_nachbar_liste = [[i, nachbar[1]] for i, \n",
    "                          nachbar in enumerate(graph_data) if i not in loesch_index]\n",
    "    return neue_nachbar_liste\n",
    "#85 Eine Funktion zum Erstellen eines Graphen aus Graphdaten\n",
    "def graph_bauer(graph_data):\n",
    "    G = nx.DiGraph()  #86 Ein gerichteter Graph wird erstellt\n",
    "    w_liste = []  #87 Eine Liste für die Gewichte wird initialisiert\n",
    "    for el in graph_data:\n",
    "        n1 = el[1][0]\n",
    "        n2 = el[1][1]\n",
    "        w = el[1][2]\n",
    "        w_liste.append(w)\n",
    "        G.add_edge(n1, n2, weight=w, title=w)\n",
    "    return G, w_liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:32.130557Z",
     "start_time": "2024-01-25T21:11:32.122432Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto_graph=cutoff_graph_data(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:12:53.897428Z",
     "start_time": "2024-01-25T21:12:53.677815Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "nx.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"nx.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1efeb0e9990>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network \n",
    "#88 Erstellen des Graphen und der Gewichtsliste mithilfe der Funktion graph_bauer\n",
    "G, W = graph_bauer(auto_graph)\n",
    "#89 Initialisieren des Netzwerk-Objekts mit der Option 'notebook=True' für die Verwendung in einem Jupyter Notebook\n",
    "nt = Network(notebook=True)\n",
    "#90 Konvertieren des NetworkX-Graphen in ein pyvis-Netzwerk\n",
    "nt.from_nx(G)\n",
    "#91 Anzeigen des Netzwerkdiagramms und Speichern als HTML-Datei mit dem Namen 'nx.html'\n",
    "nt.show('nx.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
