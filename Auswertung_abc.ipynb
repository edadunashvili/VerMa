{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Auswertung abc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README\n",
    "\n",
    "###### Tool zur Auswertung der Normalform des Märchentyps in Form von Graphen und Motivlisten\n",
    "\n",
    "Die Motivliste befindet sich am Ende dieses Notebooks. Die gleichnamige HTML-Datei wie die Variable mWert ist im Basisordner zu finden.\n",
    "\n",
    "Das Zeichen „_x“ am Ende eines Markup-Elements in der Liste weist auf die Wiederholung des Motivs hin.\n",
    "\n",
    "Variationen des Motivs, die durch den Wechsel der handlungstragenden Figuren entstehen, werden ignoriert. Ein Markup-Element besteht daher ausschließlich aus einem 3-Tupel:\n",
    "\n",
    "a = Typnummer\n",
    "\n",
    "b = Sinn und Zweck der Handlung\n",
    "\n",
    "c = die im Wortlaut erfasste Handlung\n",
    "\n",
    "##### Anpassbare Variablen:\n",
    "Variable mZahl: Die Indexnummer des betrachteten Märchentyps kann durch diese Variable angepasst werden.\n",
    "\n",
    "Variable mWert: Diese Variable bestimmt ein spezifisches Motiv als Anhaltspunkt innerhalb der visualisierten Motivkette. Der Wert wird aus der generierten Liste (siehe Zeile 149) entnommen, nachdem die Variable mZahl  festgelegt und der Code ausgeführt wurde.\n",
    "\n",
    "Variable häufigkeit: Die Variable häufigkeit legt fest, wie oft die Motive miteinander in Verbindung stehen.\n",
    "\n",
    "Pfad zur Inputdatei: Der Pfad zur Eingabedatei kann in den entsprechenden Einstellungen angepasst werden.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mZahl = \"a551\"  #1 Typnummer eingeben\n",
    "\n",
    "mWert = \"a551:h:KRANKHEIT\"  #2 Ein konkretes Markupelement eingeben\n",
    "\n",
    "haeufigkeit = 2 #3 Eine ganze Zahl eingeben = Häufigkeit eines Markupelements in den ausgewerteten Daten3\n",
    "\n",
    "def graph_update():\n",
    "    graph.update(alle_aeste(\"\", df))\n",
    "    graph.update(alle_aeste(\"\", df))\n",
    "    graph.update(alle_aeste(\"\", df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Märchendaten  wurden in 'text.csv' gespeichert.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET  # Importieren der ElementTree-Bibliothek zum Parsen von XML\n",
    "\n",
    "# XML-Daten laden\n",
    "tree = ET.parse('Textkorpus.xml')\n",
    "root_node = tree.getroot()\n",
    "\n",
    "# Namespace definieren\n",
    "NS = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "\n",
    "# Filtereinstellung für das Attribut `@ident` (kann leer sein)\n",
    "# filter_ident = \"\"  # z. B. input(\"Bitte geben Sie das Attribut 'ident' an (z.B. 'kat'): \").strip()\n",
    "\n",
    "# Variable für die gesammelten Märchendaten\n",
    "maerchen = \"\"\n",
    "\n",
    "# Iteration durch die XML-Daten\n",
    "for corp in root_node.findall(\".//tei:teiCorpus\", NS):\n",
    "    if \"\" in corp.attrib.get(\"n\", \"\"):# or \"xtk\" in corp.attrib.get(\"n\", \"\"):\n",
    "        for tei in corp.findall(\"tei:TEI\", NS):\n",
    "            # Filter basierend auf `@ident` oder bei leerem `filter_ident`\n",
    "#             language = tei.find(\".//tei:teiHeader//tei:langUsage/tei:language\", NS)\n",
    "#             if language is not None:\n",
    "#                 ident_value = language.attrib.get('ident', '')\n",
    "#                 if filter_ident == \"\" or ident_value == filter_ident:\n",
    "                    for ganze in tei.findall(\".//tei:text\", NS):\n",
    "                        quelle = ganze.attrib.get('{http://www.w3.org/XML/1998/namespace}id', '')\n",
    "                        for body in ganze.findall(\".//tei:body\", NS):\n",
    "                            for absatz in body.findall(\".//tei:p\", NS):\n",
    "                                for phrase in absatz.findall(\".//tei:seg\", NS):\n",
    "                                    # Labels extrahieren\n",
    "                                    labela = phrase.attrib.get('{www.dglab.uni-jena.de/vmf/a}ana', 'N/A')\n",
    "                                    labelb1 = phrase.attrib.get('{www.dglab.uni-jena.de/vmf/b1}ana', 'N/A')\n",
    "                                    labelb2 = phrase.attrib.get('{www.dglab.uni-jena.de/vmf/b2}ana', 'N/A')\n",
    "                                    labelb3 = phrase.attrib.get('{www.dglab.uni-jena.de/vmf/b3}ana', 'N/A')\n",
    "                                    labelb4 = phrase.attrib.get('{www.dglab.uni-jena.de/vmf/b4}ana', 'N/A')\n",
    "                                    labelb5 = phrase.attrib.get('{www.dglab.uni-jena.de/vmf/b5}ana', 'N/A')\n",
    "                                    labelc1 = phrase.attrib.get('{www.dglab.uni-jena.de/vmf/c1}ana', 'N/A')\n",
    "                                    labelc2 = phrase.attrib.get('{www.dglab.uni-jena.de/vmf/c2}ana', 'N/A')\n",
    "                                    labelc3 = phrase.attrib.get('{www.dglab.uni-jena.de/vmf/c3}ana', 'N/A')\n",
    "                                    labelc4 = phrase.attrib.get('{www.dglab.uni-jena.de/vmf/c4}ana', 'N/A')\n",
    "                                    labelc5 = phrase.attrib.get('{www.dglab.uni-jena.de/vmf/c5}ana', 'N/A')\n",
    "                                    labeld = phrase.attrib.get('{www.dglab.uni-jena.de/vmf/d}ana', 'N/A')\n",
    "                                    inhalt = (phrase.text.lower().strip()\n",
    "                                              .replace('|', '').replace(':', '').replace(\"ä\", \"ae\")\n",
    "                                              .replace(\"ü\", \"ue\").replace(\"ö\", \"oe\").replace(\"ß\", \"ss\")\n",
    "                                              .replace(\",\", \"\").replace(\"\\n\", \" \").replace(\"'\", \"\")\n",
    "                                              .replace(\"…\", \"\").replace('\"', \"\").replace(\"*\", \"\")\n",
    "                                              .replace(\"(\", \"\").replace(\")\", \"\").replace(\"-\", \"\")\n",
    "                                              .replace(\"]\", \"\").replace(\"[\", \"\").replace(\".\", \"\")\n",
    "                                              .replace(\"?\", \"\").replace(\"!\", \"\").replace(\"„\", \"\")\n",
    "                                              .replace(\"+\", \"\").replace(\"=\", \"\").replace(\"_\", \"\")\n",
    "                                              .replace(\"­\", \"\").replace('“', \"\").replace('”', \"\")\n",
    "                                              .replace(\";\", \"\").replace('~', \"\").replace('`', \"\"))\n",
    "                                    # Bedingung: labela beginnt mit 'a' und labelb1 ist nicht 'N/A'\n",
    "                                    if labela.startswith('a') and labelb1 != 'N':\n",
    "                                        # Märchendaten sammeln\n",
    "                                        maerchen += (quelle + ',' + labela + ',' + labelb1 + ',' + labelc1 + ',' +\n",
    "                                                     labelb2 + ',' + labelc2 + ',' + labelb3 + ',' + labelc3 + ',' +\n",
    "                                                     labelb4 + ',' + labelc4 + ',' + labelb5 + ',' + labelc5 + ',' +\n",
    "                                                     labeld + ',' + inhalt + ',0' + '\\n')\n",
    "\n",
    "# Ergebnisse in eine CSV-Datei schreiben\n",
    "with open(\"text.csv\", 'w', encoding='utf-8') as f:\n",
    "    # Kopfzeile schreiben\n",
    "    f.write('quelle,labela,labelb1,labelc1,labelb2,labelc2,labelb3,labelc3,labelb4,labelc4,labelb5,labelc5,labeld,inhalt,index_binar')\n",
    "    f.write('\\n')\n",
    "    # Gesammelte Märchendaten schreiben\n",
    "    f.write(maerchen)\n",
    "\n",
    "print(f\"Die Märchendaten  wurden in 'text.csv' gespeichert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20 leere Zeichenketten, in der Daten für abcd1-5 gesammelt werden.\n",
    "abcd1 = \"\"\n",
    "abcd2 = \"\"\n",
    "abcd3 = \"\"\n",
    "abcd4 = \"\"\n",
    "abcd5 = \"\"\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "#21 Einlesen der CSV-Datei in ein DataFrame.\n",
    "df = pd.read_csv('text.csv', encoding='utf-8')\n",
    "#22 Hinzufügen von Daten an abcd1, abcd2, abcd3, abcd4 und abcd5.\n",
    "abcd1 += df.quelle + ',' + df.labela + ':' + df.labelb1 + ':' + df.labelc1 + ',' + df.inhalt + ',0'\n",
    "abcd2 += df.quelle + ',' + df.labela + ':' + df.labelb2 + ':' + df.labelc2 + ',' + df.inhalt + ',0'\n",
    "abcd3 += df.quelle + ',' + df.labela + ':' + df.labelb3 + ':' + df.labelc3 + ',' + df.inhalt + ',0'\n",
    "abcd4 += df.quelle + ',' + df.labela + ':' + df.labelb4 + ':' + df.labelc4 + ',' + df.inhalt + ',0'\n",
    "abcd5 += df.quelle + ',' + df.labela + ':' + df.labelb5 + ':' + df.labelc5 + ',' + df.inhalt + ',0'\n",
    "#23 Zusammenstellen der Daten aus abcd1 bis abcd5.\n",
    "recorded = (abcd1 + '\\n' + abcd2 + '\\n' + abcd3 + '\\n' + abcd4 + '\\n' + abcd5 + '\\n')\n",
    "#24 Schreiben der aufgezeichneten Daten in eine CSV-Datei.\n",
    "with open(\"text_aw.csv\", 'w', encoding='utf-8') as w:\n",
    "    w.write('quelle,index_string,inhalt,index_binar\\n')\n",
    "    w.write('000:ballast,ballast,ballast,0\\n')  #25 Schreiben einer Platzhalterzeile.\n",
    "    w.write(\"\".join(recorded))  #26 Schreiben der aufgezeichneten Daten.\n",
    "import csv\n",
    "mom = []  #27 Eine leere Liste zum Speichern der Daten.\n",
    "\n",
    "#28 Lesen der CSV-Datei und Filtern von Zeilen mit ':N:' in der zweiten Spalte.\n",
    "with open('text_aw.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        if ':N:' not in line[1]:  #29 Wenn ':N:' nicht in der zweiten Spalte enthalten ist.\n",
    "            mom.append(line)  #30 Die Zeile der Liste mom hinzufügen.\n",
    "#31 Schreiben der gefilterten Daten in eine Textdatei.\n",
    "with open('text_ax.txt', 'wt', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(mom)  #32 Schreiben der Liste in die Datei.\n",
    "#33 Lesen der Textdatei und Formatieren der Daten.\n",
    "with open('text_ax.txt', 'r', encoding='utf-8') as file:\n",
    "    filedata = file.read()\n",
    "filedata = (filedata.replace(']\",\"[', \"\\n\").replace('\"[', '').replace(']\"', '').replace(\" '\", \"\")\n",
    "            .replace(\"'\", \"\"))\n",
    "#34 Schreiben der formatierten Daten in eine CSV-Datei.\n",
    "with open('text_ay.csv', 'w', encoding='utf-8') as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Datei zum Lesen und Schreiben festlegen\n",
    "input_file = 'text_ay.csv'   # Pfad zur Eingabedatei\n",
    "output_file = 'text_ay_mudi.csv'  # Pfad zur Ausgabedatei\n",
    "\n",
    "# Funktion, um das vierte Segment im Feld index_string zu entfernen\n",
    "def remove_fourth_segment(index_string):\n",
    "    segments = index_string.split(':')\n",
    "    if len(segments) > 3:\n",
    "        del segments[3]  # Entfernt das vierte Segment\n",
    "    return ':'.join(segments)\n",
    "\n",
    "# CSV-Datei lesen und bearbeiten\n",
    "with open(input_file, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    fieldnames = reader.fieldnames  # Spaltennamen speichern\n",
    "\n",
    "    # Bearbeitete Daten schreiben\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as csvfile_out:\n",
    "        writer = csv.DictWriter(csvfile_out, fieldnames=fieldnames)\n",
    "        writer.writeheader()  # Kopfzeile schreiben\n",
    "        \n",
    "        for row in reader:\n",
    "            # Feld 'index_string' bearbeiten\n",
    "            row['index_string'] = remove_fourth_segment(row['index_string'])\n",
    "            writer.writerow(row)  # Geänderte Zeile schreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Datei text_ay_mudi.csv wurde erfolgreich bearbeitet und gespeichert.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Pfad zur CSV-Datei\n",
    "csv_datei = 'text_ay_mudi.csv'\n",
    "\n",
    "# Datenstruktur zum Speichern der Häufigkeit der Kombinationen\n",
    "kombinationen = defaultdict(int)\n",
    "\n",
    "# Die CSV-Datei lesen und die Häufigkeit der Kombinationen zählen\n",
    "with open(csv_datei, mode='r', newline='', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    rows = list(reader)\n",
    "\n",
    "    # Zählen der Häufigkeit jeder Kombination\n",
    "    for row in rows:\n",
    "        kombination = (row['quelle'], row['index_string'])\n",
    "        kombinationen[kombination] += 1\n",
    "\n",
    "# Die Kombinationen-Häufigkeiten zurücksetzen, um die Bearbeitung durchzuführen\n",
    "kombinationen = defaultdict(int)\n",
    "\n",
    "# Die CSV-Datei bearbeiten, wobei wiederholte Kombinationen entsprechend der Häufigkeit 'x' erhalten\n",
    "for row in rows:\n",
    "    kombination = (row['quelle'], row['index_string'])\n",
    "    kombinationen[kombination] += 1\n",
    "    if kombinationen[kombination] > 1:\n",
    "        # Hängt entsprechend der Wiederholung so viele '_x' an\n",
    "        row['index_string'] += '_x' * (kombinationen[kombination] - 1) #alternativ gilt für mehrmalige '_x' \n",
    "        #row['index_string'] += '_x' #alternativ gilt für einmalige '_x' \n",
    "\n",
    "# Die bearbeitete CSV-Datei unter demselben Namen speichern\n",
    "with open(csv_datei, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=rows[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Die Datei {csv_datei} wurde erfolgreich bearbeitet und gespeichert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from collections import Counter \n",
    "df = pd.read_csv('text_ay_mudi.csv', encoding='utf-8')  #35 Einlesen der Daten aus einer CSV-Datei in ein DataFrame.\n",
    "#36 Eine Funktion zur Formatierung der Markupelemente eines Märchens.\n",
    "def ep_format(ep_full):\n",
    "    return (ep_full.split(':'))[0]\n",
    "#37 Eine Funktion zur Formatierung des Typs eines Märchens.\n",
    "def ep_name_format(ep_full):\n",
    "    sublist = (ep_full)\n",
    "    name = \"\"\n",
    "    for strg in sublist:\n",
    "        name += strg\n",
    "    return name\n",
    "#38 Eine Funktion zum Vergleich von Quellen in einem DataFrame.\n",
    "def quellenvergleich(df, i1, i2):\n",
    "    return df.quelle[i1] == df.quelle[i2]\n",
    "#39 Eine Funktion zur Analyse von Abschnitten eines Märchens.\n",
    "def ast(gesep, df):\n",
    "    ep_tree = {}  #40 Ein leeres Dictionary zur Speicherung der Analyseergebnisse.\n",
    "    a_liste = []  #41 Eine leere Liste zur Speicherung von Startabschnitten.\n",
    "    z_liste = []  #42 Eine leere Liste zur Speicherung von Endabschnitten.\n",
    "    df_len = len(df.index_string)  # Die Anzahl der Zeilen im DataFrame.\n",
    "    for i, ep in enumerate(df.index_string):  #43 Iteration durch die 'Index-String' des DataFrames.\n",
    "        if gesep == ep:  #44 Wenn der aktuelle Abschnitt dem gesuchten Abschnitt entspricht.\n",
    "            if (i > 0) and (quellenvergleich(df, i, i - 1)):  #45 Wenn es einen vorherigen Abschnitt gibt und die Quellen übereinstimmen.\n",
    "                a = df.index_string[i - 1]  #46 Der vorherige Abschnitt wird als Startabschnitt betrachtet.\n",
    "            else:\n",
    "                a = 'Anf-' + ep_name_format(gesep)  #47 Ansonsten wird ein neuer Startabschnitt erstellt.\n",
    "            if (i < df_len - 1):  #48 Wenn es einen nächsten Abschnitt gibt.\n",
    "                if not (quellenvergleich(df, i, i + 1)):  #49 Wenn die Quellen des nächsten Abschnitts unterschiedlich sind.\n",
    "                    z = 'End-' + ep_name_format(gesep)  #50 Der aktuelle Abschnitt wird als Endabschnitt betrachtet.\n",
    "                else:\n",
    "                    z = df.index_string[i + 1]  #51 Ansonsten wird der nächste Abschnitt als Endabschnitt betrachtet.\n",
    "            else:\n",
    "                z = 'End-' + ep_name_format(gesep)  #52 Wenn es keinen nächsten Abschnitt gibt, wird ein neuer Endabschnitt erstellt.\n",
    "            a_liste.append(a)  #53 Startabschnitt wird der Liste hinzugefügt.\n",
    "            z_liste.append(z)  #54 Endabschnitt wird der Liste hinzugefügt.\n",
    "    return {gesep: [Counter(a_liste), Counter(z_liste)]}  #55 Rückgabe der Analyseergebnisse als Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alle_aeste(gesep, df):\n",
    "    episoden_baeume = {}  #56 Ein leeres Dictionary zur Speicherung der Analyseergebnisse.\n",
    "    ep_list = []  #57 Eine leere Liste zur Speicherung von Episoden.\n",
    "    for ep_full in df.index_string:  #58 Iteration durch die 'Index-String' des DataFrames.\n",
    "        ep = ep_format(ep_full)  #59 Formatierung der Episode.\n",
    "        if gesep == ep:  #60 Wenn die gesuchte Episode gefunden wird.\n",
    "            ep_list.append(ep_full)  #61 Die Episode wird zur Liste hinzugefügt.\n",
    "    for ep in set(ep_list):  #62 Iteration durch jede einzigartige Episode in der Liste.\n",
    "        episoden_baeume.update(ast(ep, df))  #63 Die Analyseergebnisse für jede Episode werden dem Dictionary hinzugefügt.\n",
    "    return episoden_baeume  #64 Rückgabe des Dictionary mit den Analyseergebnissen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#63 Die Variable 'graph' wird mit den Analyseergebnissen für die Episode 'mZahl' initialisiert.\n",
    "graph = alle_aeste(mZahl, df)\n",
    "graph_update()\n",
    "#wald_printer(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:11:31.249124Z",
     "start_time": "2024-01-25T21:11:30.925952Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import networkx as nx \n",
    "#66 Eine Funktion zum Filtern von Daten für einen bestimmten Ast.\n",
    "def cutoff_ast_data(wuerzel, graph, nachbar_liste, cutoff=0):\n",
    "    vor = graph[wuerzel][0]  #67 Vorwärtsverbindungen des Astes.\n",
    "    zurueck = graph[wuerzel][1]  #68 Rückwärtsverbindungen des Astes.\n",
    "    nachbarn = vor.copy()  #69 Kopie der Vorwärtsverbindungen.\n",
    "    nachbarn.update(zurueck)  #70 Hinzufügen der Rückwärtsverbindungen.\n",
    "    for ast_name, ast_gewicht in sorted(nachbarn.items()):  #71 Iteration durch die Nachbarn des Astes.\n",
    "        if (ast_gewicht >= cutoff):  #72 Wenn das Gewicht größer oder gleich dem Cutoff-Wert ist.\n",
    "            nachbar_liste.append([ep_name_format(wuerzel),\n",
    "                                   ep_name_format(ast_name), ast_gewicht])  #73 Die Verbindung wird der Nachbarliste hinzugefügt.\n",
    "#74 Eine Funktion zum Filtern von Daten für den gesamten Graphen.\n",
    "def cutoff_graph_data(graph, cutoff=0):\n",
    "    nachbar_liste = []  #75 Eine leere Liste zur Speicherung der Nachbarn.\n",
    "    for i, (k, v) in enumerate(sorted(graph.items())):  #76 Iteration durch die Elemente des Graphen.\n",
    "        cutoff_ast_data(k, graph, nachbar_liste, cutoff)  #77 Filtern der Daten für jeden Ast.\n",
    "    neue_nachbar_liste = [[i, nachbar] for i, nachbar in enumerate(nachbar_liste)]  #78 Indexierung der Nachbarn.\n",
    "    return neue_nachbar_liste  #79 Rückgabe der gefilterten Nachbardaten.\n",
    "#80 Eine Funktion zur Aktualisierung der interaktiven Daten des Graphen.\n",
    "def interactive_graph_data(graph_data, loesch_index, gew_dict):\n",
    "    for k, v in gew_dict.items():  #81 Iteration durch die Gewichts-Daten.\n",
    "        graph_data[k][1][2] = v  #82 Aktualisieren der Gewichts-Daten.\n",
    "    neue_nachbar_liste = [[i, nachbar[1]] for i,\n",
    "                          nachbar in enumerate(graph_data) if i not in loesch_index]  #83 Filtern der Daten.\n",
    "    return neue_nachbar_liste  #84 Rückgabe der aktualisierten Daten.\n",
    "\n",
    "#85 Eine Funktion zum Aufbau des Graphen aus den Daten.\n",
    "def graph_bauer(graph_data):\n",
    "    G = nx.Graph()  #86 Initialisierung eines gerichteten Graphen.\n",
    "    w_liste = []  #87 Eine leere Liste zur Speicherung der Gewichts-Daten.\n",
    "    for el in graph_data:  #88 Iteration durch die Elemente der Graphendaten.\n",
    "        n1 = el[1][0]  #89 Der Ausgangsknoten der Verbindung.\n",
    "        n2 = el[1][1]  #90 Der Zielknoten der Verbindung.\n",
    "        w = el[1][2]  #91 Das Gewicht der Verbindung.\n",
    "        w_liste.append(w)  #92 Hinzufügen des Gewichts zur Liste.\n",
    "        #93 Hinzufügen der Verbindung und der Knoten zum Graphen.\n",
    "        G.add_edge(n1, n2, weight=w, title=w)\n",
    "        G.add_edge(n1, n2, weight=w, title=w)\n",
    "        G.add_node(n1, title=n1, size=15)\n",
    "        G.add_node(n2, title=n2, size=15)\n",
    "    return G, w_liste  #94 Rückgabe des Graphen und der Gewichtsliste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#95 Filtern der Graphendaten basierend auf der Häufigkeit.\n",
    "auto_graph = cutoff_graph_data(graph, haeufigkeit)\n",
    "G, W = graph_bauer(auto_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T21:12:53.897428Z",
     "start_time": "2024-01-25T21:12:53.677815Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyvis.network import Network \n",
    "#96 Erstellen des Graphen und der Gewichtsliste aus den Graphendaten.\n",
    "G, W = graph_bauer(auto_graph)\n",
    "\n",
    "#97 Erstellen einer Network-Instanz für die Visualisierung des Graphen.\n",
    "nt = Network(notebook=True,  #98 Das Netzwerk wird im Jupyter Notebook angezeigt.\n",
    "             height='650px',  #99 Höhe des Netzwerks.\n",
    "             width='1300px',  #100 Breite des Netzwerks.\n",
    "             directed=False,  #101 Der Graph ist ungerichtet.\n",
    "             neighborhood_highlight=True,\n",
    "             bgcolor='#ffffff',  #102 Hintergrundfarbe des Netzwerks.\n",
    "             font_color='black',  #103 Die Farbe der Schrift im Netzwerk wird automatisch festgelegt.\n",
    "             layout=None,  #104 Die Layout-Eigenschaft wird nicht gesetzt (standardmäßig wird ein Fruchterman-Reingold-Layout verwendet).\n",
    "             heading='',  #105 Ein leerer Titel für das Netzwerk.\n",
    "             filter_menu=True,\n",
    "             select_menu=True,\n",
    "             cdn_resources='in_line')  #106 Die Ressourcen werden lokal geladen (ohne Internetverbindung).\n",
    "#107 Fügen Sie die Knoten und Kanten des Graphen zur Netzwerkinstanz hinzu.\n",
    "nt.from_nx(G)\n",
    "\n",
    "#108 Anzeigen des Netzwerks im Jupyter Notebook.\n",
    "with open('auswertung_abc.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(nt.generate_html())  # Erzeugt HTML mit UTF-8 Unterstützung\n",
    "#nt.show('nx.html')  #109 Die Visualisierung wird in einer HTML-Datei gespeichert und im Notebook angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "#110 Eine Funktion zur Überprüfung, ob ein Nachbar in einen Knoten einbezogen werden kann.\n",
    "def neighbour_is_includable(node, neighbour):\n",
    "    designation = \":\".join(node.split(\":\")[0:1])  #111 Extrahieren der Bezeichnung des Knotens.\n",
    "    return neighbour.startswith(designation)  #112 Rückgabe, ob der Nachbar in den Knoten einbezogen werden kann.\n",
    "#113 Eine Funktion zur Bereinigung der Kanten basierend auf der Einbeziehbarkeit.\n",
    "def pruned_edges(node, neighbours):\n",
    "    return [neighbor for neighbor in neighbours if neighbour_is_includable(node, neighbor)]\n",
    "#114 Eine Funktion zur Erstellung eines bereinigten Graphen.\n",
    "def make_pruned_graph(graph):\n",
    "    pruned_graph = {}\n",
    "    for node, (incoming, outgoing) in graph.items():\n",
    "        pruned_incoming = pruned_edges(node, incoming)\n",
    "        pruned_outgoing = pruned_edges(node, outgoing)\n",
    "        pruned_graph[node] = (pruned_incoming, pruned_outgoing)\n",
    "    return pruned_graph\n",
    "#115 Eine Funktion zur Erstellung eines gerichteten Rückgrat-Graphen.\n",
    "def make_backbone_di_graph(pruned_graph):\n",
    "    new_DiGraph = nx.DiGraph()\n",
    "    for node, (incoming, outgoing) in pruned_graph.items():\n",
    "        for in_node in incoming:\n",
    "            new_DiGraph.add_edge(in_node, node)\n",
    "        for out_node in outgoing:\n",
    "            new_DiGraph.add_edge(node, out_node)\n",
    "    return new_DiGraph\n",
    "#116 Eine Funktion zur Berechnung der kürzesten Pfade mit Vorzeichen.\n",
    "def signed_shortest_path_length(G, source, target):\n",
    "    try:\n",
    "        pl = nx.dijkstra_path_length(G, source=source, target=target)\n",
    "    except nx.NodeNotFound:\n",
    "        pl = np.Inf\n",
    "    except nx.NetworkXNoPath:\n",
    "        try:\n",
    "            pl = - nx.dijkstra_path_length(G, source=target, target=source)\n",
    "        except nx.NodeNotFound:\n",
    "            pl = np.Inf\n",
    "        except nx.NetworkXNoPath:\n",
    "            pl = np.Inf\n",
    "    return pl\n",
    "#117 Eine Funktion zur Erstellung von Distanzdaten für Hauptknoten.\n",
    "def create_main_node_distances(start_node, pruned_graph, graph, nx_graph):\n",
    "    distances = { key:[] for key in graph}\n",
    "    backbone_di_graph= make_backbone_di_graph(pruned_graph)\n",
    "    for node in pruned_graph:\n",
    "        distances[node] = {signed_shortest_path_length(backbone_di_graph, start_node, node)}\n",
    "    return distances\n",
    "#118 Eine Funktion zum Hinzufügen von Distanzdaten für Unter- bzw. Nebenknoten.\n",
    "def add_sub_node_distances(node, sub_nodes, pruned_graph, distances, d):\n",
    "    for sub_node in sub_nodes:\n",
    "        if sub_node not in pruned_graph.keys():\n",
    "            if sub_node not in distances:\n",
    "                distances[sub_node] = set()\n",
    "            new_dists = {dist + d for dist in distances[node]}\n",
    "            distances[sub_node].update(new_dists)\n",
    "#119 Eine Funktion zur Erstellung eines Distanz-Dictionarys.\n",
    "def create_distance_dict(start_node, graph, G):\n",
    "    pruned_graph = make_pruned_graph(graph)\n",
    "    distances = create_main_node_distances(start_node, pruned_graph, graph, G)\n",
    "    for node, (incoming, outgoing) in graph.items():\n",
    "        add_sub_node_distances(node, incoming, pruned_graph, distances, -1)\n",
    "        add_sub_node_distances(node, outgoing, pruned_graph, distances, 1)\n",
    "    return distances\n",
    "#120 Startknoten für die Berechnung der Distanzen.\n",
    "start_node = mWert\n",
    "#121 Erstellen der Distanzdaten.\n",
    "distances = create_distance_dict(start_node, graph,  G)\n",
    "#122 Sortieren der Distanzdaten nach den minimalen Distanzen.\n",
    "sorted_keys = sorted(distances, key=lambda x: min(distances[x]))\n",
    "sorted_distances = {key: distances[key] for key in sorted_keys}\n",
    "#123 Konvertierung der Distanzdaten in eine Zeichenfolge für den HTML-Output.\n",
    "msia=\"\"\n",
    "tai = []\n",
    "for k, v in sorted_distances.items():\n",
    "    sia=(f\"{k} {v}\")\n",
    "    msia+=sia+'<br>'\n",
    "    tai.append(sia)\n",
    "    #print(sia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#124 Pfad zur CSV-Datei\n",
    "csv_file_path = 'output_1.csv'\n",
    "#125 Schreibe die Daten in die CSV-Datei\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')  \n",
    "    #126 Schreibe die Überschrift (Header) in die CSV-Datei\n",
    "    writer.writerow(['Data'])\n",
    "    #127 Schreibe die Zeilen in die CSV-Datei\n",
    "    for data in tai:\n",
    "        writer.writerow([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#128 Diese Funktion erstellt eine Menge aus den ausgewählten Knoten basierend auf den Kanten im Graphen.\n",
    "def make_set_of_chosen_vertices(graph_edge_data):\n",
    "    chosen_vertices = set()  #129 Initialisierung einer leeren Menge für ausgewählte Knoten\n",
    "    for sub_list in graph_edge_data:  #130 Iteration durch die Kanten im Graphen\n",
    "        sub_sub_list = sub_list[1]  #131 Die Kanteninformationen befinden sich in der zweiten Unterliste\n",
    "        chosen_vertices.add(sub_sub_list[0])  #132 Hinzufügen des ersten Knotens der Kante zur Menge ausgewählter Knoten\n",
    "        chosen_vertices.add(sub_sub_list[1])  #133 Hinzufügen des zweiten Knotens der Kante zur Menge ausgewählter Knoten\n",
    "    return chosen_vertices  #134 Rückgabe der Menge ausgewählter Knoten\n",
    "\n",
    "dat = []  #135 Initialisierung einer leeren Liste 'dat' für Daten\n",
    "\n",
    "#136 'graph_data' enthält die Informationen über die Kanten im Graphen, basierend auf einer bestimmten Häufigkeitsschwelle ('haeufigkeit')\n",
    "graph_data = cutoff_graph_data(graph, haeufigkeit)\n",
    "\n",
    "#137 Die ausgewählten Knoten werden aus der Menge ausgewählt und sortiert\n",
    "chosen_vertices = list(make_set_of_chosen_vertices(graph_data))  \n",
    "#chosen_vertices.sort()  \n",
    "\n",
    "#138 Iteration durch die ausgewählten Knoten\n",
    "for vertex_name in chosen_vertices:\n",
    "    dat.append(vertex_name)  # Hinzufügen des Knotennamens zur Liste 'dat'\n",
    "csv_file_path = 'output_2.csv'\n",
    "#139 Schreibe die Daten in die CSV-Datei\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')    \n",
    "    #140 Schreibe die Überschrift (Header) in die CSV-Datei\n",
    "    writer.writerow([''])\n",
    "    #141 Schreibe die Zeilen in die CSV-Datei\n",
    "    for data in dat:\n",
    "        writer.writerow([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typ = a551\n",
      "Referenz-Motiv = a551:h:KRANKHEIT\n",
      "Häufigkeit = 2\n",
      "\n",
      "Anf-a551:h:KRANKHEIT {-1}\n",
      "a551:h:KRANKHEIT {0}\n",
      "a551:F:HEILMITTEL_besorgen {1}\n",
      "a551:F:Zu_Beauftragungen_anregen {1}\n",
      "a551:f:VERLOCKUNG {2}\n",
      "a551:F:Um_einen_Auftrag_WERBEN {2}\n",
      "a551:H:REITTIER_erhalten_x_x {3}\n",
      "a551:H:IDENTITÄT_beweisen {3}\n",
      "a551:Hh:Auf_WERBEN_reagieren {3}\n",
      "a551:h:Auf_VERLOCKUNG_reagieren {3}\n",
      "a551:HF:HEILMITTEL_erfassen {3}\n",
      "a551:H:Heiraten {4}\n",
      "a551:H:REITTIER_erhalten {4}\n",
      "a551:H:Potenziellen_Feind_zum_Gastgeber_gewinnen_x_x {4}\n",
      "a551:h:FREIHEITSBERAUBUNG {4}\n",
      "a551:f:VERLOCKUNG_x {4}\n",
      "a551:Hh:Beiwohnung_mit_der_Schönen {4}\n",
      "a551:H:Potenziellen_Feind_zum_Gastgeber_gewinnen {4}\n",
      "a551:f:VERLOCKUNG_x_x {4}\n",
      "a551:H:KONTAKT_wiederherstellen {4}\n",
      "a551:HF:PFÖRTNER_besänftigen {4}\n",
      "a551:F:MARKIERUNGEN_anbringen {5}\n",
      "a551:HF:Weiterverweisung_an_anderen_Stifter_oder_Helfer {5}\n",
      "a551:h:Auf_VERLOCKUNG_reagieren_x {5}\n",
      "a551:H:HEILMITTEL_erfassen {5}\n",
      "a551:H:Bestrafung {5}\n",
      "a551:H:Auf_VERLOCKUNG_reagieren {5}\n",
      "End-a551:H:Heiraten {5}\n",
      "a551:h:KONTAKT_abbrechen {6}\n",
      "a551:H:REITTIER_erhalten_x {6}\n",
      "a551:H:Potenziellen_Feind_zum_Gastgeber_gewinnen_x {6}\n",
      "a551:h:FREIHEITSBERAUBUNG_x {6}\n",
      "End-a551:H:Bestrafung {6}\n",
      "a551:h:SCHLAF {7}\n",
      "a551:h:ANEIGNUNG {8}\n",
      "a551:h:ZAUBERMITTEL_AUSRÜSTUNG_oder_WAFFE_austauschen {8}\n",
      "a551:H:HEILMITTEL_besorgen {9}\n",
      "a551:Hh:HEILMITTEL_besorgen {9}\n",
      "a551:H:MARKIERUNGEN_erkennen {10}\n",
      "a551:H:KRANKHEIT_beheben {10}\n",
      "a551:h:KRANKHEIT_beheben {10}\n",
      "a551:F:IDENTITÄT_beweisen_x {11}\n",
      "a551:F:KONTAKT_wiederherstellen {11}\n",
      "a551:h:VEREINBARUNG_einhalten {11}\n",
      "a551:F:IDENTITÄT_beweisen {12}\n",
      "a551:h:IDENTITÄT_beweisen {12}\n"
     ]
    }
   ],
   "source": [
    "#142 Liste a\n",
    "sia_a=[]\n",
    "with open('output_1.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f) \n",
    "    for line in reader:\n",
    "            sia_a.append(line)\n",
    "#143 Liste b\n",
    "sia_b=[]         \n",
    "with open('output_2.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f) \n",
    "    for line in reader:\n",
    "            sia_b.append(line)\n",
    "#144 Liste c\n",
    "sia_c=[]\n",
    "#145 Iteriere durch Liste a\n",
    "for element_a in sia_a:\n",
    "    #146 Extrahiere den auftlinken String aus dem ersten Element in Liste a\n",
    "    left_string_a = element_a[0].split(' ')[0]\n",
    "\n",
    "    #147 Überprüfe, ob der linke String aus Liste a in Liste b vorhanden ist\n",
    "    if any(left_string_a in element_b[0] for element_b in sia_b):\n",
    "        #148 Wenn ja, füge das aktuelle Element aus Liste a zu Liste c hinzu\n",
    "        sia_c.append(element_a[0])\n",
    "#149 Ausgabe der generierten Liste c\n",
    "print(f'Typ = {mZahl}\\nReferenz-Motiv = {mWert}\\nHäufigkeit = {haeufigkeit}\\n')\n",
    "for element_c in sia_c:\n",
    "    print(element_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
